# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RnIWX7QIWCjdmXweuNUSfcYhYjYfI0eH
"""

#kütüphanelerin çağırılması kodları çalıştırdığımızda gösterilen hata değil uyarıdır çalışma durumunu etkilemez.
!pip install yfinance
import pandas as pd
import math

import pandas
from pandas_datareader import data as pdr
import yfinance as yfin
yfin.pdr_override()
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import  MinMaxScaler
from keras.models import Sequential 
from keras.layers import Dense,LSTM
plt.style.use('fivethirtyeight')

"""# Yeni Bölüm"""

#df dataframemiz yani datalarımız(verilerimiz) çekmek istediğimiz bölüm  2010 tarihinden 2022 tarihine kadar verilerimizi çekmek istiyoruz verileri yahhodan alıyoruz.
df=pdr.get_data_yahoo('USDTRY=X',start='2010-05-24',end='2022-04-22')
print(df)

#Borsada günlük açılış ve kapanış fiyatları ve günün en yüksek ve en düşük değerleri vardır bu kodlar altında kapanış fiyatlarını tabloluyoruz.
plt.figure(figsize=(16,8))
plt.title("Kapanış Fiyatları Tarihsel")
plt.plot(df['Close'])
plt.xlabel('Tarih',fontsize=18)
plt.ylabel('USDTRY Kapanış Fiyatları',fontsize=18)

#kapanış fiyatlarıyla ilgili yeni bir data oluşturuyoruz.
#match ceil ile Kendisine geçirilen  parametre değerinden küçük olmayan en küçük int değeri hesaplayarak yukarı yuvarlama işlemi yapar.
data=df.filter(['Close'])   
dataset=data.values
training_data_len=math.ceil(len(dataset)*.8)
training_data_len

#Değerimizden o veri aralığındaki minimum değeri çıkartıyoruz, aralık değerine bölüyoruz.
scaler=MinMaxScaler(feature_range=(0,1))  
scaled_data=scaler.fit_transform(dataset)
scaled_data

#Tüm veri kümesi sütunlarınızı ölçeklendiriyorsunuz.
train_data=scaled_data[0:training_data_len, :]   
x_train=[]
y_train=[]
#61. kapanış fiyatı değerini tahmin etmek için kullanmak istediğimiz son 60 günlük kapanış fiyatı değerlerini içeren bir eğitim veri seti oluşturun.
#Dolayısıyla, ' x_train ' veri setindeki ilk sütun, indeks 0'dan indeks 59'a kadar olan veri setinden (toplam 60 değer) değerleri içerecek ve ikinci kolon, indeks 1'den indeks 60'a (60 değer) kadar olan veri setinden değerleri içerecektir. ve saire ve saire.
#' y_train ' veri seti, birinci sütunu için indeks 60'ta yer alan 61. değeri ve ikinci değeri için veri setinin indeks 61'inde bulunan 62. değeri vb. içerecektir.
for i in range(60, len(train_data)):
   x_train.append(train_data[i-60:i,0])
   y_train.append(train_data[i,0])
   if i <=61:
     print(x_train)
     print(y_train)
     print()

#Şimdi bağımsız  veri kümesini ' x_train ' ve bağımlı  veri kümesini ' y_train ' numpy dizilerine dönüştürün, böylece LSTM modelini eğitmek için kullanılabilirler.
x_train,y_train=np.array(x_train),np.array(y_train) #

#Veriyi [ örnek sayısı , zaman adımı sayısı ve özellik sayısı ] biçiminde 3 boyutlu olacak şekilde yeniden şekillendirin . LSTM modeli 3 boyutlu bir veri seti bekliyor.
x_train=np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))  
x_train.shape

#50 nöronlu iki LSTM katmanına ve biri 25 nöronlu, diğeri 1 nöronlu iki Yoğun katmana sahip olacak şekilde LSTM modelini oluşturduk.
model=Sequential()
model.add(LSTM(50,return_sequences=True,input_shape=(x_train.shape[1],1)))   
model.add(LSTM(50,return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

#Ortalama kare hatası (MSE) kayıp işlevini ve adam optimize ediciyi kullanarak modeli derledik.
model.compile(optimizer='Adam',loss='mean_squared_error')

#Eğitim veri kümelerini kullanarak modeli eğittik.   #emre
#Dikkat, fit, trenin başka bir adıdır. Toplu iş boyutu, tek bir grupta bulunan toplam eğitim örneklerinin sayısıdır ve dönem, tüm bir veri kümesinin sinir ağı üzerinden ileri ve geri iletildiği yinelemelerin sayısıdır.

#Bir test veri seti oluşturalım  #emre
#Test veri seti
test_data=scaled_data[training_data_len - 60:,:]
#x_test ve y_test veri kümelerini oluşturalım
x_test=[]
y_test=dataset[training_data_len:,:]
for y in range (60,len(test_data)):
   x_test.append(test_data[y-60:y, 0])

#LSTM modelini test etmek için kullanılabilmesi için bağımsız test veri kümesi ' x_test'i bir numpy dizisine dönüştürün.
#x_test'i sayısal bir diziye dönüştürelim  #emre
x_test=np.array(x_test)

#Veriyi [ örnek sayısı , zaman adımı sayısı ve özellik sayısı ] biçiminde 3 boyutlu olacak şekilde yeniden şekillendirin .
#Bunun yapılması gerekiyor çünkü LSTM modeli 3 boyutlu bir veri seti bekliyor  
#aşşağıda Verileri, LSTM tarafından kabul edilen şekle yeniden şekillendirdik.
x_test=np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))

#Şimdi test verilerini kullanarak modelden tahmin edilen değerleri alıcaz
#Modellerin tahmini fiyat değerlerini   #emre
predictions=model.predict(x_test)
predictions=scaler.inverse_transform(predictions)

#Modelin ne kadar doğru olduğunun iyi bir ölçüsü olan ortalama karesel hatanın (RMSE) kökünü alın. 0 değeri, modellerin tahmin edilen değerlerinin, test veri setindeki gerçek değerlerle mükemmel bir şekilde eşleştiğini gösterir.
#Değer ne kadar düşük olursa model o kadar iyi performans gösterir. Ancak, modelin ne kadar iyi performans gösterdiğine dair gerçekten bir fikir edinmek için genellikle diğer ölçümleri de kullanmak en iyisidir.
#aşşağıda rmse değerini hesaplayıp alalım  
rmse=np.sqrt(np.mean(predictions - y_test)**2)
rmse

#Verileri çizelim ve görselleştirelim.  #gizem

##Plot/Grafik dizisi için verileri oluşturun
train=data[:training_data_len]
valid=data[training_data_len:]         
valid['Tahminler']=predictions
##Verileri görselleştirin
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Tarih',Fontsize=18)
plt.ylabel('Kapanış Fiyatları',fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close','Tahminler']])
plt.legend(['Eğitilen Alan','Değer','Tahminler'],loc='lower right')
plt.show()

#PROJENİN ASIL AMACI BURADA ANLATIYORUM BURAYI İYİ OKUYUN.ŞİMDİ BORSA DA AÇÇILIŞ VE KAPANIŞ FİYATLARI OLDUĞU İÇİN AÇILIN FİYATLARINI EĞİTTİK EĞİTTİĞİMİZ AÇILIŞ FİYATLARIYLA 
#KAPANIŞ FİYATLARINI PYTHON İLE TAHMİN ETMEYE ÇALIŞTIK.